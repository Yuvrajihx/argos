import convict from 'convict';
import { execSync } from 'node:child_process';
import { existsSync, readFileSync, createReadStream } from 'node:fs';
import axios from 'axios';
import createDebug from 'debug';
import { resolve } from 'node:path';
import glob from 'fast-glob';
import { promisify } from 'node:util';
import sharp from 'sharp';
import tmp from 'tmp';
import { createHash } from 'node:crypto';
import { readFile } from 'node:fs/promises';
import { readMetadata, getPlaywrightTracePath } from '@argos-ci/util';

const getPrNumber$2 = ({ env })=>{
    return env.BITRISE_PULL_REQUEST ? Number(env.BITRISE_PULL_REQUEST) : null;
};
const service$7 = {
    name: "Bitrise",
    detect: ({ env })=>Boolean(env.BITRISE_IO),
    config: ({ env })=>{
        return {
            commit: env.BITRISE_GIT_COMMIT || null,
            branch: env.BITRISE_GIT_BRANCH || null,
            owner: env.BITRISEIO_GIT_REPOSITORY_OWNER || null,
            repository: env.BITRISEIO_GIT_REPOSITORY_SLUG || null,
            jobId: null,
            runId: null,
            prNumber: getPrNumber$2({
                env
            }),
            prHeadCommit: null,
            nonce: env.BITRISEIO_PIPELINE_ID || null
        };
    }
};

/**
 * Check if the current directory is a git repository.
 */ const checkIsGitRepository = ()=>{
    try {
        return execSync("git rev-parse --is-inside-work-tree").toString().trim() === "true";
    } catch  {
        return false;
    }
};
/**
 * Returns the head commit.
 */ const head = ()=>{
    try {
        return execSync("git rev-parse HEAD").toString().trim();
    } catch  {
        return null;
    }
};
/**
 * Returns the current branch.
 */ const branch = ()=>{
    try {
        const headRef = execSync("git rev-parse --abbrev-ref HEAD").toString().trim();
        if (headRef === "HEAD") {
            return null;
        }
        return headRef;
    } catch  {
        return null;
    }
};

const service$6 = {
    name: "Buildkite",
    detect: ({ env })=>Boolean(env.BUILDKITE),
    config: ({ env })=>{
        return {
            // Buildkite doesn't work well so we fallback to git to ensure we have commit and branch
            commit: env.BUILDKITE_COMMIT || head() || null,
            branch: env.BUILDKITE_BRANCH || branch() || null,
            owner: env.BUILDKITE_ORGANIZATION_SLUG || null,
            repository: env.BUILDKITE_PROJECT_SLUG || null,
            jobId: null,
            runId: null,
            prNumber: env.BUILDKITE_PULL_REQUEST ? Number(env.BUILDKITE_PULL_REQUEST) : null,
            prHeadCommit: null,
            nonce: env.BUILDKITE_BUILD_ID || null
        };
    }
};

const service$5 = {
    name: "Heroku",
    detect: ({ env })=>Boolean(env.HEROKU_TEST_RUN_ID),
    config: ({ env })=>({
            commit: env.HEROKU_TEST_RUN_COMMIT_VERSION || null,
            branch: env.HEROKU_TEST_RUN_BRANCH || null,
            owner: null,
            repository: null,
            jobId: null,
            runId: null,
            prNumber: null,
            prHeadCommit: null,
            nonce: env.HEROKU_TEST_RUN_ID || null
        })
};

const KEY = "@argos-ci/core";
const debug = createDebug(KEY);
const debugTime = (arg)=>{
    const enabled = createDebug.enabled(KEY);
    if (enabled) {
        console.time(arg);
    }
};
const debugTimeEnd = (arg)=>{
    const enabled = createDebug.enabled(KEY);
    if (enabled) {
        console.timeEnd(arg);
    }
};

/**
 * Get a pull request from a head sha.
 * Fetch the last 30 pull requests sorted by updated date
 * then try to find the one that matches the head sha.
 * If no pull request is found, return null.
 */ async function getPullRequestFromHeadSha({ env }, sha) {
    debug("Fetching pull request number from head sha", sha);
    if (!env.GITHUB_REPOSITORY) {
        throw new Error("GITHUB_REPOSITORY is missing");
    }
    if (!env.GITHUB_TOKEN) {
        // For security reasons, people doesn't want to expose their GITHUB_TOKEN
        // That's why we allow to disable this warning.
        if (!env.DISABLE_GITHUB_TOKEN_WARNING) {
            console.log(`
Running argos from a "deployment_status" event requires a GITHUB_TOKEN.
Please add \`GITHUB_TOKEN: \${{ secrets.GITHUB_TOKEN }}\` as environment variable.

Read more at https://argos-ci.com/docs/run-on-preview-deployment

To disable this warning, add \`DISABLE_GITHUB_TOKEN_WARNING: true\` as environment variable.
`.trim());
        }
        return null;
    }
    try {
        const result = await axios.get(`https://api.github.com/repos/${env.GITHUB_REPOSITORY}/pulls`, {
            params: {
                state: "open",
                sort: "updated",
                per_page: 30,
                page: 1
            },
            headers: {
                Accept: "application/vnd.github+json",
                Authorization: `Bearer ${process.env.GITHUB_TOKEN}`,
                "X-GitHub-Api-Version": "2022-11-28"
            }
        });
        if (result.data.length === 0) {
            debug("Aborting because no pull request found");
            return null;
        }
        const matchingPr = result.data.find((pr)=>pr.head.sha === sha);
        if (matchingPr) {
            debug("Pull request found", matchingPr);
            return matchingPr;
        }
        debug("Aborting because no pull request found");
        return null;
    } catch (error) {
        debug("Error while fetching pull request from head sha", error);
        return null;
    }
}
const getBranch = ({ env })=>{
    if (env.GITHUB_HEAD_REF) {
        return env.GITHUB_HEAD_REF;
    }
    const branchRegex = /refs\/heads\/(.*)/;
    if (!env.GITHUB_REF) {
        return null;
    }
    const matches = branchRegex.exec(env.GITHUB_REF);
    return (matches === null || matches === void 0 ? void 0 : matches[1]) ?? null;
};
const getRepository$1 = ({ env })=>{
    if (!env.GITHUB_REPOSITORY) return null;
    return env.GITHUB_REPOSITORY.split("/")[1];
};
const readEventPayload = ({ env })=>{
    if (!env.GITHUB_EVENT_PATH) return null;
    if (!existsSync(env.GITHUB_EVENT_PATH)) return null;
    return JSON.parse(readFileSync(env.GITHUB_EVENT_PATH, "utf-8"));
};
const service$4 = {
    name: "GitHub Actions",
    detect: ({ env })=>Boolean(env.GITHUB_ACTIONS),
    config: async ({ env })=>{
        var _payload_pull_request, _payload_pull_request1, _payload_pull_request2;
        const payload = readEventPayload({
            env
        });
        const sha = process.env.GITHUB_SHA || null;
        if (!sha) {
            throw new Error(`GITHUB_SHA is missing`);
        }
        const commonConfig = {
            commit: sha,
            owner: env.GITHUB_REPOSITORY_OWNER || null,
            repository: getRepository$1({
                env
            }),
            jobId: env.GITHUB_JOB || null,
            runId: env.GITHUB_RUN_ID || null,
            nonce: `${env.GITHUB_RUN_ID}-${env.GITHUB_RUN_ATTEMPT}` || null
        };
        // If the job is triggered by from a "deployment" or a "deployment_status"
        if (payload === null || payload === void 0 ? void 0 : payload.deployment) {
            debug("Deployment event detected");
            // Try to find a relevant pull request for the sha
            const pullRequest = await getPullRequestFromHeadSha({
                env
            }, sha);
            return {
                ...commonConfig,
                // If no pull request is found, we fallback to the deployment environment as branch name
                // Branch name is required to create a build but has no real impact on the build.
                branch: (pullRequest === null || pullRequest === void 0 ? void 0 : pullRequest.head.ref) || payload.deployment.environment || null,
                prNumber: (pullRequest === null || pullRequest === void 0 ? void 0 : pullRequest.number) || null,
                prHeadCommit: (pullRequest === null || pullRequest === void 0 ? void 0 : pullRequest.head.sha) || null
            };
        }
        return {
            ...commonConfig,
            branch: (payload === null || payload === void 0 ? void 0 : (_payload_pull_request = payload.pull_request) === null || _payload_pull_request === void 0 ? void 0 : _payload_pull_request.head.ref) || getBranch({
                env
            }) || null,
            prNumber: (payload === null || payload === void 0 ? void 0 : (_payload_pull_request1 = payload.pull_request) === null || _payload_pull_request1 === void 0 ? void 0 : _payload_pull_request1.number) || null,
            prHeadCommit: (payload === null || payload === void 0 ? void 0 : (_payload_pull_request2 = payload.pull_request) === null || _payload_pull_request2 === void 0 ? void 0 : _payload_pull_request2.head.sha) ?? null
        };
    }
};

const getPrNumber$1 = ({ env })=>{
    const branchRegex = /pull\/(\d+)/;
    const matches = branchRegex.exec(env.CIRCLE_PULL_REQUEST || "");
    if (matches) {
        return Number(matches[1]);
    }
    return null;
};
const service$3 = {
    name: "CircleCI",
    detect: ({ env })=>Boolean(env.CIRCLECI),
    config: ({ env })=>{
        return {
            commit: env.CIRCLE_SHA1 || null,
            branch: env.CIRCLE_BRANCH || null,
            owner: env.CIRCLE_PROJECT_USERNAME || null,
            repository: env.CIRCLE_PROJECT_REPONAME || null,
            jobId: null,
            runId: null,
            prNumber: getPrNumber$1({
                env
            }),
            prHeadCommit: null,
            nonce: env.CIRCLE_WORKFLOW_ID || env.CIRCLE_BUILD_NUM || null
        };
    }
};

const getOwner = ({ env })=>{
    if (!env.TRAVIS_REPO_SLUG) return null;
    return env.TRAVIS_REPO_SLUG.split("/")[0] || null;
};
const getRepository = ({ env })=>{
    if (!env.TRAVIS_REPO_SLUG) return null;
    return env.TRAVIS_REPO_SLUG.split("/")[1] || null;
};
const getPrNumber = ({ env })=>{
    if (env.TRAVIS_PULL_REQUEST) return Number(env.TRAVIS_PULL_REQUEST);
    return null;
};
const service$2 = {
    name: "Travis CI",
    detect: ({ env })=>Boolean(env.TRAVIS),
    config: (ctx)=>{
        const { env } = ctx;
        return {
            commit: env.TRAVIS_COMMIT || null,
            branch: env.TRAVIS_BRANCH || null,
            owner: getOwner(ctx),
            repository: getRepository(ctx),
            jobId: null,
            runId: null,
            prNumber: getPrNumber(ctx),
            prHeadCommit: null,
            nonce: env.TRAVIS_BUILD_ID || null
        };
    }
};

const service$1 = {
    name: "GitLab",
    detect: ({ env })=>env.GITLAB_CI === "true",
    config: ({ env })=>{
        return {
            commit: env.CI_COMMIT_SHA || null,
            branch: env.CI_COMMIT_REF_NAME || null,
            owner: null,
            repository: null,
            jobId: null,
            runId: null,
            prNumber: null,
            prHeadCommit: null,
            nonce: env.CI_PIPELINE_ID || null
        };
    }
};

const service = {
    name: "Git",
    detect: ()=>checkIsGitRepository(),
    config: ()=>{
        return {
            commit: head() || null,
            branch: branch() || null,
            owner: null,
            repository: null,
            jobId: null,
            runId: null,
            prNumber: null,
            prHeadCommit: null,
            nonce: null
        };
    }
};

// List of services ordered by usage
// "git" must be the last one
const services = [
    service$5,
    service$4,
    service$3,
    service$2,
    service$6,
    service$1,
    service$7,
    service
];
async function getCiEnvironment({ env = process.env } = {}) {
    const ctx = {
        env
    };
    debug("Detecting CI environment", {
        env
    });
    const service = services.find((service)=>service.detect(ctx));
    // Service matched
    if (service) {
        debug("Internal service matched", service.name);
        const variables = await service.config(ctx);
        const ciEnvironment = {
            name: service.name,
            ...variables
        };
        debug("CI environment", ciEnvironment);
        return ciEnvironment;
    }
    return null;
}

const mustBeApiBaseUrl = (value)=>{
    const URL_REGEX = /https?:\/\/(www\.)?[-a-zA-Z0-9@:%._\+~#=]{1,256}\.[a-zA-Z0-9()]{1,6}\b([-a-zA-Z0-9()@:%_\+.~#?&//=]*)/;
    if (!URL_REGEX.test(value)) {
        throw new Error("Invalid Argos API base URL");
    }
};
const mustBeCommit = (value)=>{
    const SHA1_REGEX = /^[0-9a-f]{40}$/;
    if (!SHA1_REGEX.test(value)) {
        const SHA1_SHORT_REGEX = /^[0-9a-f]{7}$/;
        if (SHA1_SHORT_REGEX.test(value)) {
            throw new Error("Short SHA1 is not allowed");
        }
        throw new Error("Invalid commit");
    }
};
const mustBeArgosToken = (value)=>{
    if (value && value.length !== 40) {
        throw new Error("Invalid Argos repository token (must be 40 characters)");
    }
};
const schema = {
    apiBaseUrl: {
        env: "ARGOS_API_BASE_URL",
        default: "https://api.argos-ci.com/v2/",
        format: mustBeApiBaseUrl
    },
    commit: {
        env: "ARGOS_COMMIT",
        default: null,
        format: mustBeCommit
    },
    branch: {
        env: "ARGOS_BRANCH",
        default: null,
        format: String
    },
    token: {
        env: "ARGOS_TOKEN",
        default: null,
        format: mustBeArgosToken
    },
    buildName: {
        env: "ARGOS_BUILD_NAME",
        default: null,
        format: String,
        nullable: true
    },
    prNumber: {
        env: "ARGOS_PR_NUMBER",
        format: Number,
        default: null,
        nullable: true
    },
    prHeadCommit: {
        env: "ARGOS_PR_HEAD_COMMIT",
        format: String,
        default: null,
        nullable: true
    },
    parallel: {
        env: "ARGOS_PARALLEL",
        default: false,
        format: Boolean
    },
    parallelNonce: {
        env: "ARGOS_PARALLEL_NONCE",
        format: String,
        default: null,
        nullable: true
    },
    parallelTotal: {
        env: "ARGOS_PARALLEL_TOTAL",
        format: "nat",
        default: null,
        nullable: true
    },
    referenceBranch: {
        env: "ARGOS_REFERENCE_BRANCH",
        format: String,
        default: null,
        nullable: true
    },
    referenceCommit: {
        env: "ARGOS_REFERENCE_COMMIT",
        format: String,
        default: null,
        nullable: true
    },
    ciService: {
        format: String,
        default: null,
        nullable: true
    },
    jobId: {
        format: String,
        default: null,
        nullable: true
    },
    runId: {
        format: String,
        default: null,
        nullable: true
    },
    owner: {
        format: String,
        default: null,
        nullable: true
    },
    repository: {
        format: String,
        default: null,
        nullable: true
    }
};
const createConfig = ()=>{
    return convict(schema, {
        args: []
    });
};
async function readConfig(options = {}) {
    const config = createConfig();
    const ciEnv = await getCiEnvironment();
    config.load({
        apiBaseUrl: options.apiBaseUrl || config.get("apiBaseUrl"),
        commit: options.commit || config.get("commit") || (ciEnv === null || ciEnv === void 0 ? void 0 : ciEnv.commit) || null,
        branch: options.branch || config.get("branch") || (ciEnv === null || ciEnv === void 0 ? void 0 : ciEnv.branch) || null,
        token: options.token || config.get("token") || null,
        buildName: options.buildName || config.get("buildName") || null,
        prNumber: options.prNumber || config.get("prNumber") || (ciEnv === null || ciEnv === void 0 ? void 0 : ciEnv.prNumber) || null,
        prHeadCommit: config.get("prHeadCommit") || (ciEnv === null || ciEnv === void 0 ? void 0 : ciEnv.prHeadCommit) || null,
        referenceBranch: options.referenceBranch || config.get("referenceBranch") || null,
        referenceCommit: options.referenceCommit || config.get("referenceCommit") || null,
        ciService: (ciEnv === null || ciEnv === void 0 ? void 0 : ciEnv.name) || null,
        owner: (ciEnv === null || ciEnv === void 0 ? void 0 : ciEnv.owner) || null,
        repository: (ciEnv === null || ciEnv === void 0 ? void 0 : ciEnv.repository) || null,
        jobId: (ciEnv === null || ciEnv === void 0 ? void 0 : ciEnv.jobId) || null,
        runId: (ciEnv === null || ciEnv === void 0 ? void 0 : ciEnv.runId) || null,
        parallel: options.parallel ?? config.get("parallel") ?? false,
        parallelNonce: options.parallelNonce || config.get("parallelNonce") || (ciEnv === null || ciEnv === void 0 ? void 0 : ciEnv.nonce) || null,
        parallelTotal: options.parallelTotal || config.get("parallelTotal") || null
    });
    config.validate();
    return config.get();
}

const discoverScreenshots = async (patterns, { root = process.cwd(), ignore } = {})=>{
    const matches = await glob(patterns, {
        onlyFiles: true,
        ignore,
        cwd: root
    });
    return matches.map((match)=>{
        const path = resolve(root, match);
        return {
            name: match,
            path
        };
    });
};

const tmpFile = promisify(tmp.file);
const optimizeScreenshot = async (filepath)=>{
    try {
        const resultFilePath = await tmpFile();
        await sharp(filepath).resize(2048, 20480, {
            fit: "inside",
            withoutEnlargement: true
        }).png({
            force: true
        }).toFile(resultFilePath);
        return resultFilePath;
    } catch (error) {
        const message = error instanceof Error ? error.message : "Unknown Error";
        throw new Error(`Error while processing image (${filepath}): ${message}`, {
            cause: error
        });
    }
};

const hashFile = async (filepath)=>{
    const fileStream = createReadStream(filepath);
    const hash = createHash("sha256");
    await new Promise((resolve, reject)=>{
        fileStream.on("error", reject);
        hash.on("error", reject);
        hash.on("finish", resolve);
        fileStream.pipe(hash);
    });
    return hash.digest("hex");
};

const base64Encode = (obj)=>Buffer.from(JSON.stringify(obj), "utf8").toString("base64");
const getBearerToken = ({ token, ciService, owner, repository, jobId, runId, prNumber })=>{
    if (token) return `Bearer ${token}`;
    switch(ciService){
        case "GitHub Actions":
            {
                if (!owner || !repository || !jobId || !runId) {
                    throw new Error(`Automatic ${ciService} variables detection failed. Please add the 'ARGOS_TOKEN'`);
                }
                return `Bearer tokenless-github-${base64Encode({
                    owner,
                    repository,
                    jobId,
                    runId,
                    prNumber
                })}`;
            }
        default:
            throw new Error("Missing Argos repository token 'ARGOS_TOKEN'");
    }
};
const createArgosApiClient = (options)=>{
    const axiosInstance = axios.create({
        baseURL: options.baseUrl,
        headers: {
            Authorization: options.bearerToken,
            "Content-Type": "application/json",
            Accept: "application/json"
        }
    });
    const call = async (method, path, data)=>{
        try {
            debug("Sending request", {
                method,
                path,
                data
            });
            const response = await axiosInstance.request({
                method,
                url: path,
                data
            });
            debug("Getting response", {
                status: response.status,
                data: response.data
            });
            return response.data;
        } catch (error) {
            var _error_response_data_error, _error_response_data, _error_response;
            if (error === null || error === void 0 ? void 0 : (_error_response = error.response) === null || _error_response === void 0 ? void 0 : (_error_response_data = _error_response.data) === null || _error_response_data === void 0 ? void 0 : (_error_response_data_error = _error_response_data.error) === null || _error_response_data_error === void 0 ? void 0 : _error_response_data_error.message) {
                // @ts-ignore
                throw new Error(error.response.data.error.message, {
                    cause: error
                });
            }
            throw error;
        }
    };
    return {
        createBuild: async (input)=>{
            return call("POST", "/builds", input);
        },
        updateBuild: async (input)=>{
            const { buildId, ...body } = input;
            return call("PUT", `/builds/${buildId}`, body);
        }
    };
};

const upload$1 = async (input)=>{
    const file = await readFile(input.path);
    await axios({
        method: "PUT",
        url: input.url,
        data: file,
        headers: {
            "Content-Type": input.contentType
        }
    });
};

/**
 * Split an array into chunks of a given size.
 */ const chunk = (collection, size)=>{
    const result = [];
    // add each chunk to the result
    for(let x = 0; x < Math.ceil(collection.length / size); x++){
        let start = x * size;
        let end = start + size;
        result.push(collection.slice(start, end));
    }
    return result;
};

/**
 * Size of the chunks used to upload screenshots to Argos.
 */ const CHUNK_SIZE = 10;
async function getConfigFromOptions({ parallel, ...options }) {
    return readConfig({
        ...options,
        parallel: Boolean(parallel),
        parallelNonce: parallel ? parallel.nonce : null,
        parallelTotal: parallel ? parallel.total : null
    });
}
async function uploadFilesToS3(files) {
    debug(`Split files in chunks of ${CHUNK_SIZE}`);
    const chunks = chunk(files, CHUNK_SIZE);
    debug(`Starting upload of ${chunks.length} chunks`);
    for(let i = 0; i < chunks.length; i++){
        // Upload files
        debug(`Uploading chunk ${i + 1}/${chunks.length}`);
        const timeLabel = `Chunk ${i + 1}/${chunks.length}`;
        debugTime(timeLabel);
        await Promise.all(chunks[i].map(async ({ url, path, contentType })=>{
            await upload$1({
                url,
                path,
                contentType
            });
        }));
        debugTimeEnd(timeLabel);
    }
}
/**
 * Upload screenshots to argos-ci.com.
 */ async function upload(params) {
    var _result_pwTraces;
    debug("Starting upload with params", params);
    // Read config
    const config = await getConfigFromOptions(params);
    const files = params.files ?? [
        "**/*.{png,jpg,jpeg}"
    ];
    debug("Using config and files", config, files);
    const apiClient = createArgosApiClient({
        baseUrl: config.apiBaseUrl,
        bearerToken: getBearerToken(config)
    });
    // Collect screenshots
    const foundScreenshots = await discoverScreenshots(files, {
        root: params.root,
        ignore: params.ignore
    });
    debug("Found screenshots", foundScreenshots);
    // Optimize & compute hashes
    const screenshots = await Promise.all(foundScreenshots.map(async (screenshot)=>{
        const [metadata, pwTracePath, optimizedPath] = await Promise.all([
            readMetadata(screenshot.path),
            getPlaywrightTracePath(screenshot.path),
            optimizeScreenshot(screenshot.path)
        ]);
        const [hash, pwTraceHash] = await Promise.all([
            hashFile(optimizedPath),
            pwTracePath ? hashFile(pwTracePath) : null
        ]);
        return {
            ...screenshot,
            hash,
            optimizedPath,
            metadata,
            pwTrace: pwTracePath && pwTraceHash ? {
                path: pwTracePath,
                hash: pwTraceHash
            } : null
        };
    }));
    // Create build
    debug("Creating build");
    const [pwTraceKeys, screenshotKeys] = screenshots.reduce(([pwTraceKeys, screenshotKeys], screenshot)=>{
        if (screenshot.pwTrace && !pwTraceKeys.includes(screenshot.pwTrace.hash)) {
            pwTraceKeys.push(screenshot.pwTrace.hash);
        }
        if (!screenshotKeys.includes(screenshot.hash)) {
            screenshotKeys.push(screenshot.hash);
        }
        return [
            pwTraceKeys,
            screenshotKeys
        ];
    }, [
        [],
        []
    ]);
    const result = await apiClient.createBuild({
        commit: config.commit,
        branch: config.branch,
        name: config.buildName,
        parallel: config.parallel,
        parallelNonce: config.parallelNonce,
        screenshotKeys,
        pwTraceKeys,
        prNumber: config.prNumber,
        prHeadCommit: config.prHeadCommit,
        referenceBranch: config.referenceBranch,
        referenceCommit: config.referenceCommit
    });
    debug("Got uploads url", result);
    const uploadFiles = [
        ...result.screenshots.map(({ key, putUrl })=>{
            const screenshot = screenshots.find((s)=>s.hash === key);
            if (!screenshot) {
                throw new Error(`Invariant: screenshot with hash ${key} not found`);
            }
            return {
                url: putUrl,
                path: screenshot.optimizedPath,
                contentType: "image/png"
            };
        }),
        ...((_result_pwTraces = result.pwTraces) === null || _result_pwTraces === void 0 ? void 0 : _result_pwTraces.map(({ key, putUrl })=>{
            const screenshot = screenshots.find((s)=>s.pwTrace && s.pwTrace.hash === key);
            if (!screenshot || !screenshot.pwTrace) {
                throw new Error(`Invariant: trace with ${key} not found`);
            }
            return {
                url: putUrl,
                path: screenshot.pwTrace.path,
                contentType: "application/json"
            };
        })) ?? []
    ];
    await uploadFilesToS3(uploadFiles);
    // Update build
    debug("Updating build");
    await apiClient.updateBuild({
        buildId: result.build.id,
        screenshots: screenshots.map((screenshot)=>{
            var _screenshot_pwTrace;
            return {
                key: screenshot.hash,
                name: screenshot.name,
                metadata: screenshot.metadata,
                pwTraceKey: ((_screenshot_pwTrace = screenshot.pwTrace) === null || _screenshot_pwTrace === void 0 ? void 0 : _screenshot_pwTrace.hash) ?? null
            };
        }),
        parallel: config.parallel,
        parallelTotal: config.parallelTotal
    });
    return {
        build: result.build,
        screenshots
    };
}

export { readConfig, upload };
